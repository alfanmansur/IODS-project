---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Chapter 6 Analysis of longitudinal data

Here, we intend to do the analysis of longitudinal data as in the textbook of Multivariate Analysis for the Behavioral Sciences (MABS) by Vehkalahti and
Everitt (2019) Chapter 8 and 9. The difference between this exercise and the original analysis in the textbook is that we swap the dataset, i.e. using the RATS data in the analyses of Chapter 8 of MABS and using the BPRS data in the analyses of Chapter 9 of MABS.

We use the following R packages: 

```{r, results="hide", message=FALSE, warning=FALSE, error=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
```

## 6.1. Implement the analyses of Chapter 8 of MABS using the RATS data

We start with preparing the dataset which we have also conducted in the previous data wrangling exercise.

```{r}
# read the RATS data
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')
# Factor variables ID and Group in RATS data
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
# Convert to long form and add a Time variable to RATS
RATSL <- RATS %>%
  gather(key = WD, value = Weight, -ID, -Group) %>%
  mutate(Time = as.integer(substr(WD,3,4))) 
```

```{r}
# Check the dimensions of the data
dim(RATSL)

# Plot the RATSL data
ggplot(RATSL, aes(x = Time, y = Weight, group = ID)) +
  geom_line(aes(linetype = Group)) +
  scale_x_continuous(name = "Time (days)", breaks = seq(0, 60, 10)) +
  scale_y_continuous(name = "Weight (grams)") +
  theme(legend.position = "top")
```
\
In the RATS dataset, there are three kind of treatments that can bee seen from the plot above as group 1, group 2, and group three. The weight (in grams) of the rats is on y-axis plotted against time (in days) on x-axis.
\

### Figure 8.1 Individual response profiles by treatment group for the RATS data

We continue with plotting individual response profiles by group of treatments for the RATS data. A number of graphical displays including this one is useful in assessing longitudinal data which contains 'repeated measures'.

From the plot below, we can identify that there are substantial individual differences and variability seems to increase with time. Also, there appears significant gains in weight from treatment 1 to treatment 2 and 3 despite a possibility of existent outliers in the group of treatment 2.

```{r}
p1 <- ggplot(RATSL, aes(x = Time, y = Weight, linetype = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(limits = c(min(RATSL$Weight), max(RATSL$Weight)))
p6
```
\

### Figure 8.2 Individual response profiles for RATS data after standardization

Here, we standardize the weight by subtracting from its mean and then dividing by its standard deviation. Now, the trending variability over time looks gone, but the gains from treatment 1 to treatment 2 and 3 remain.

```{r}
# Standardize the scores:
RATSL <- RATSL %>%
  group_by(Time) %>%
  mutate( stdrats = (Weight - mean(Weight))/sd(Weight) ) %>%
  ungroup()
glimpse(RATSL)
p1 <- ggplot(RATSL, aes(x = Time, y = stdrats, linetype = ID))
p2 <- p1 + geom_line() + scale_linetype_manual(values = rep(1:10, times=4))
p3 <- p2 + facet_grid(. ~ Group, labeller = label_both)
p4 <- p3 + theme_bw() + theme(legend.position = "none")
p5 <- p4 + theme(panel.grid.minor.y = element_blank())
p6 <- p5 + scale_y_continuous(name = "standardized Weight")
p6
```
\

### Figure 8.3 Mean response profiles for the three treatment groups in the RATS data

Next, we perform summary measure analysis by plotting the mean response profiles for the three treatment groups in the RATS data. The plot essentially take the mean of individual responses forming one series of mean, so we can see its behavior overtime. As we can see from the plot below, it trends up overtime and we can see a significant gain in weight from treatment 1 to treatment 2 and 3.

```{r}
# Number of subjects (per group):
n <- 20
# Make a summary data:
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise( mean=mean(Weight), se=sd(Weight)/sqrt(n) ) %>%
  ungroup()
glimpse(RATSS)
p1 <- ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group))
p2 <- p1 + geom_line() + scale_linetype_manual(values = c(1,2,3))
p3 <- p2 + geom_point(size=3) + scale_shape_manual(values = c(1,2,3))
p4 <- p3 + geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3)
p5 <- p4 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p6 <- p5 + theme(legend.position = c(0.8,0.5))
p7 <- p6 + scale_y_continuous(name = "mean(Weight) +/- se(Weight)")
p7
```
\

### Figure 8.4 Boxplots for the RATS data

Another summary measure analysis that we can do is by displaying boxplots. Basically, every single boxplot contains information of the lowest point, the highest point, the most populated points, and the mean, hence we can gather lots of information. From the boxplots below, we can see the same patterns as before, i.e. trending up variability overtime and significant gains in weight in treatment 2 and 3. One additional information that we can see are the outliers as displayed the black dots.

```{r}
p1 <- ggplot(RATSL, aes(x = factor(Time), y = Weight, fill = Group))
p2 <- p1 + geom_boxplot(position = position_dodge(width = 0.9))
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + theme(legend.position = c(0.8,0.4))
p5 <- p4 + scale_x_discrete(name = "Time")
# Black & White version:
#p6 <- p5 + scale_fill_grey(start = 0.5, end = 1)
p5
```
\

### Figure 8.5 Boxplots of mean summary measures for the three treatment groups in the RATS data

Next, rather than displaying the boxplots of weight against time, we here plot by group of treatments, i.e. 3 groups. As before, we see the significant gains in weight from treatment 1 to treatment 2 and 3.

```{r}
# Make a summary data of the post treatment Times (1-8)
RATSL8S <- RATSL %>%
  filter(Time > 0) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()
glimpse(RATSL8S)
p1 <- ggplot(RATSL8S, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white")
p5 <- p4 + scale_y_continuous(name = "mean(Weight), days 1-8")
p5
```

\

### Figure 8.6 Boxplots of mean summary measures for the three treatment groups in the RATS data, without the outlier shown in Figure 8.5

Here, we remove the outlier in group 2, i.e. filter out the weight > 550 grams. The informations here is still the same as before, except the removed outlier in group 2.

```{r}
# Remove the outlier:
RATSL8S1 <- RATSL8S %>%
  filter(mean < 550)
glimpse(RATSL8S1)
p1 <- ggplot(RATSL8S1, aes(x = Group, y = mean))
p2 <- p1 + geom_boxplot()
p3 <- p2 + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4 <- p3 + stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white")
p5 <- p4 + scale_y_continuous(name = "mean(Weight), Times 1-8")
p5
```
\

### Table 8.3 Independent Samples t-test on the Mean Summary Measure for the RATS Data, Without the Outlier Shown in Figure 8.5

Next, we perform a formal test for a difference. We apply a pairwise _t_-test to assess any difference between the treatment groups. As we can see from the results below, we have significant evidence for group differences.


```{r, results="hide", message=FALSE, warning=FALSE, error=FALSE}
library(rstatix)
library(ggpubr)
```
```{r}
# Get summary statistic
RATSL8S1 %>%
  group_by(Group) %>%
  get_summary_stats(mean, type = "mean_sd")
# Pairwise t-tests
pwt <- RATSL8S1 %>%
  pairwise_t_test(mean ~ Group, p.adjust.method = "bonferroni")
pwt
```

### Table 8.4 Analysis of Covariance of the RATS Data with Baseline RATS and Treatment Groups as Covariates

Finally, here we perform analysis of covariance of the RATS Data with treatment 1 as baseline and treatment 2 and 3 as covariates. From the Analysis of Variance Table, we can see that we have a strong evidence of a treatment difference.

```{r}
# Add the baseline from the original data as a new variable to the summary data:
baseline <- RATS$WD1
RATSL8S2 <- RATSL8S %>%
  mutate(baseline)
# Fit the ANCOVA model and see the results:
fit <- lm(mean ~ baseline + Group, data = RATSL8S2)
summary(fit)
anova(fit)
```


## 6.2. Implement the analyses of Chapter 9 of MABS using the BPRS data

In this section, we do analyses using Linear Mixed Effects Models for Normal Response Variables as in Kimmo's text book Chapter 9. The difference here is that we use BPRS data instead of RATS data. As the authors have pointed out, the main objective of the analyses is to characterize change in the repeated values of the response variable and to determine the explanatory variables most associated with any change.

Again, we firstly prepare the dataset as we have done in the data wrangling exercise.

```{r}
# Read the BPRS data
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
# Factor variables 'treatment' and 'subject' in BPRS data
BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)
# Convert the data sets to long form and add a week variable to BPRS
BPRSL <-  BPRS %>% gather(key = weeks, value = bprs, -treatment, -subject) 
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5,5)))
```

\

### Table 9.1: Bprs Recorded Over a 9-Time Period

If we ignore the longitudinal nature of the data, we have the following structure displayed below. It shows that we have 40 observations of 11 variables and it can be misunderstood.

```{r, echo=TRUE}
BPRS <- within(BPRS, {
       subject <- factor(subject)
    treatment <- factor(treatment)
})
glimpse(BPRS)
```
\

### Table 9.2 Long Form of the Data

Then, in the following we consider the longitudinal nature of the data and we display the first 6 obervations and the last 6 observations. We can see now that we have 360 observations of 5 variables and that we have two treatment groups. This is the correct structure of the data that we are going to use for analysis.

```{r, echo=TRUE}
glimpse(BPRSL)
head(BPRSL); tail(BPRSL)
```
\

### Figure 9.1 Plot of bprs against week for bprs data

Here again, we plot the bprs against week ignoring the repeated-measures structure of the data but identifying the group to which each observation belongs. From the plot, we see no difference between bprs of group 1 and group 2.

```{r, echo=TRUE}
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, group = subject))
p2 <- p1 + geom_text(aes(label = treatment))
p3 <- p2 + scale_x_continuous(name = "Week", breaks = seq(0, 60, 10))
p4 <- p3 + scale_y_continuous(name = "bprs")
p5 <- p4 + theme_bw()
p6 <- p5 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p6
```
\

\

### Figure 9.2 Plot of individual bprs profiles

If we plot individual responses of bprs per treatment, we can see the following. Overall, there appears a slightly declining pattern overtime and not much difference from treatment 1 to treatment 2. 

```{r}
# Draw the plot
p1 <- ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))
p1
```


\

### Table 9.3 Fitting a Linear Regression Model Ignoring the Repeated-Measures Structure of the Data

Here, we show what happens if we fit a linear regression model ignoring the repeated measures structure of the data. We fit a linear regression model to BPRS data with bprs as response variable, and treatment and week as explanatory variables. As in usual OLS regression, we model the following

\
$y_{ij}=\beta_0+t_j+\beta_1 x_{1ij}+\beta_2 x_{2ij}+...+\beta_K x_{Kij}+\varepsilon_{ij},\quad i=1,2,...,n,\quad \text{and}\quad j=1,2,...,r$.\

where $\y_{ij}$ represents the value of the individual responses at time $t_j$. However, independence assumption seems likely not to hold for repeated measures data.


```{r, echo=TRUE}
BPRS_reg <- lm(bprs ~ week + treatment, data = BPRSL)
summary(BPRS_reg)
```
```{r}
# display the actual coefficients
equatiomatic::extract_eq(BPRS_reg, use_coefs = TRUE)

```
From the results, the intercept and time variable ('week', in this case) are found significant, but the treatment 2 doesn't give any significant difference.

\

### Figure 9.3 Scatterplot matrix of repeated measures in bprs data


Let's now we see the scatter plot below where we plot the repeated
measures of bprs. From the plot, we see evidence that the repeated measures are not independent of one another.


```{r, echo=TRUE, fig.width=10, fig.height=10}
pairs(BPRS[, 3:11], cex = 0.7)
```


\

### Table 9.4 Fitting Random Intercept Model, with week and treatment as Explanatory Variables, to BPRS Data

Now, we model using Linear Mixed-Effects Models estimated using maximum likelihood, with the R package "lme4". Basically, we model the following:

\
$y_{ij}=(\beta_0+u_i)+\beta_1t_j+\beta_2D_{i1}+\varepsilon_{ij}$
\

where $y_{ij}$ represents the $i$th observation at time $j$, $u_i$ is the random effect specific to the $i$th subject normally distributed with zero mean variance $\sigma_u^2$. $\varepsilon_{ij}$ is the error term normally distributed with zero mean and variance $\sigma^2$. $D_{1i}$ is the dummy variable used to code the treatment group 2. 

```{r, results="hide", message=FALSE, warning=FALSE, error=FALSE}
library("lme4")
```

```{r, echo=TRUE}
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref)

```

```{r}
# display the actual coefficients
equatiomatic::extract_eq(BPRS_ref, use_coefs = TRUE)

```

From the results, we have similar results to the previous (the simple OLS linear regression) where the intercept and time variable ('week') are significant, but not the treatment 2. We also get similar estimates of coefficients, but with smaller standard errors on the time variable ('week') and the group treatment variable ('treatment2'). In addition, we have confirmation of negative correlation of 'week' with response variable and the intercept.


\

### Table 9.5 Fitting the Random Intercept and Slope Model, with week and treatment as Explanatory Variables, to BPRS Data

Next, we fit the random intercept and random slope model to the bprs data. The model has the form of the following:

\
$y_{ij}=(\beta_0+u_i)+(\beta_1+v_i)t_j+\beta_2D_{i1}+\varepsilon_{ij}$
\

where the extra term from the random intercept model is the random effect $v_i$
that allows the linear regression fits for each individual to differ in slope. These random effects are assumed normally distributed with zero mean and variance $\sigma_v^2$ and are allowed to be correlated with the $u_i$ random intercept effects.

```{r, echo=TRUE}
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref1)

```

```{r}
# display the actual coefficients
equatiomatic::extract_eq(BPRS_ref1, use_coefs = TRUE)
# anova
anova(BPRS_ref1, BPRS_ref)
```
The results of the fixed effects are very similar to the previous results. Then, when we perform the likelihood ratio test for the random intercept model versus the random intercept and slope model gives a chi-squared statistic of 7.27 with 2 degrees of freedom (DF) (the two additional parameters in the latter model are the variance of the $v$ random effects and the covariance of the $u$ and $v$ random effects). At 1% level, the random intercept and slope model is a better fit for the data.

\

### Table 9.6 Fitting the Random Intercept and Slope Model that Allows for a treatment Ã— week Interaction to BPRS Data

Finally, we fit a random intercept and slope model that allows for a group $\times$ time interaction. This model takes the following form:

\
$y_{ij}=(\beta_0+u_i)+(\beta_1+v_i)t_j+\beta_2D_{i1}+\beta_3(D_{i1}\times t_j)+\varepsilon_{ij}$
\

where $\beta_3(D_{i1}\times t_j)$ is the additional term compared to the previous model.

```{r, echo=TRUE}
BPRS_ref2 <- lmer(bprs ~ week * treatment + (week | subject), data = BPRSL, REML = FALSE)
summary(BPRS_ref2)
```

```{r}
# display the actual coefficients
equatiomatic::extract_eq(BPRS_ref2, use_coefs = TRUE)
# anova
anova(BPRS_ref1, BPRS_ref2)
```
The likelihood ratio test of the interaction random intercept and slope model against the corresponding model without an interaction is 3.17 with 2 DF. Given the small $p$-value, we conclude that the interaction model provides a better fit for the data, at 5%.

\

### Figure 9.4 Fitted bprs profiles from the interaction model and observed bprs profiles

Here we plot the fitted bprs profiles from the interaction model and observed bprs profiles for each of the treatment group. The interaction model seems fitting the observed data quite well.

```{r}
# Draw the plot
Fitted <- fitted(BPRS_ref2)
BPRSL <- BPRSL %>% mutate(Fitted)
# Fitted from the model
graph2 <- ggplot(BPRSL, aes(x = week, y = Fitted, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRSL$Fitted), max(BPRSL$Fitted)))
# the Observed
graph1 <- ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))
graph1; graph2
```



_*This is the end of the report. That's all folks!*_

```{r}
date()

```


