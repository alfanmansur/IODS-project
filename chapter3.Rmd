---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Chapter 3 Logistic regression

*Summary of the week (completed work and learning)*

In this Chapter we work on data from two questionnaires related to student performance (especially including alcohol consumption). We cover two parts: (1) data wrangling and (2) data analysis with logistic regression.\

* In data wrangling, we join two data sets together and create an analysis dataset (.csv file) using an R script.\

* In data analysis, we study the relationships between high/low alcohol consumption and some of the other variables in the data.\

* This report follows the following logic: R script used --> ouputs --> explanations.

### Part 1: data wrangling

We join two data sets together and create an analysis dataset for the analysis exercise. To produce the dataset, see **create_alc.R** file in the folder **data** here: https://github.com/alfanmansur/IODS-project/tree/master/data.
And the dataset produced is **data_alc.csv** file in the same folder.

### Part 2: data analysis with logistic regression

In this part, We use the following R packages to produce the intended outputs: 

```{r, results="hide", message=FALSE}
library(janitor) # this is to do cross tabulations
library(ggplot2) # this is to produce bar and box-plots, together with the next one. 
library(ggpubr)  # this is to combine plots in one frame
library(dplyr)
library(caret)   # this is to perform cross validations
```

We then proceed by firstly run the R script, print some outputs and then read the outputs.

## 3.1 Explore the data

We start with exploring the dataset including its structure and summary.

```{r}

# Read the data from my local folder
mydata <- read.csv('./data/data_alc.csv')

# Read the data from url link (only for checking purpose)
data <- read.csv("https://github.com/rsund/IODS-project/raw/master/data/alc.csv", 
                 header = TRUE, sep = ",")
# Comparing those two datasets, my constructed dataset is just exactly the same as the dataset given in the link, except the variables ending with ".p" or ".m" which I don't include in my dataset as we don't need them for analysis.

colnames(mydata)  #to see the names of all variables in the dataset
```
```{r, results="hide", , message=FALSE}
summary <- summary(mydata)   #to see the summary of each variable, but is unnecessary to display all the details in the report
str(mydata)      #to see the data structure
```
\
**Brief description about the dataset** \

The original source of the data is here: https://archive.ics.uci.edu/ml/datasets/Student+Performance. This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por) which then we join the two datasets becoming one dataset as we use for the analysis in the next section. There are originally 33 attributes and then we construct 2 additional attributes, i.e. (1) alcohol consumption which is the average of the answers related to weekday and weekend alcohol consumption, and (2) logical class of data for attribute of high consumption of alcohol defined by attribute of alcohol consumption >2. Altogether, we have 370 observations of 35 attributes. The detail description of the original 33 attributes can be seen in the provided link. 

## 3.2 Explore the distributions of the variables

To study the relationships between high/low alcohol consumption and some of the other variables, we start with choosing 4 variables from the dataset and we present our personal hypothesis about their relationships with alcohol consumption. **First**, **_age_**, our hypothesis is that the younger the student is, the more he/she will consume alcohol as the ages range between 15-22 years old. Teenagers usually are curious to try many things. **Second**, **_famrel (quality of family relationships)_**, our hypothesis is that the higher quality, the less a student consumes alcohol since he/she will have more time spent with family. Third, **_goout (going out with friends)_**, our hypothesis is that the more frequent going out with friends, the more consumption of alcohol is. Finally, **_health (current health status)_**, our hypothesis is that a student with a bad health condition will consume less alcohol.

Let's now we numerically and graphically explore the distributions of the chosen variables and their relationships with alcohol consumption using: \
1. cross-tabulations, and \
2. bar and box plots. \

The Cross-tabulations of alcohol consumption with age given below counts the amount of alcohol consumed per age. It indicates that students 15-17 years old consume more alcohol than older students and students aged 17 has the highest level of high alcohol consumption (>2). More or less, this is in line with our hypothesis previously.

```{r}
#tabyl(mydata, age, alc_use, high_use) %>%
#  adorn_percentages("row") %>%
#  adorn_pct_formatting(digits = 2)
tabyl(mydata, age, alc_use, high_use)
```
\
Next, the cross-tabulations of alcohol consumption with family relation given below show that the better quality of family relationships, the more alcohol being consumed, both average consumption and high consumption (>2). It contradicts with our previous hypothesis. It seems that we, as a data scientist, need to understand further the possibility of cultural aspect of consuming alcohol.

```{r}
tabyl(mydata, famrel, alc_use, high_use)
```
\
Next, the cross-tabulations of alcohol consumption with 'go out with friends' given below indicate that consuming alcohol has not much to do with the frequency of going out with friends. Albeit so, there maybe a slight correlation that the more going out with friends is associated with high consumption of alcohol which is in line with our previous hypothesis.

```{r}
tabyl(mydata, goout, alc_use, high_use)
```

Finally, the cross-tabulations of alcohol consumption with health given below show that higher level of health is associated with higher consumption of alcohol which is in line with our hypothesis.

```{r}
tabyl(mydata, health, alc_use, high_use)
```

We next analyze further using bar-plots and box-plots in the figure below. There are four panels in the figure: (A) the plots of average alcohol consumption and age, (B) the plots of average alcohol consumption and family relationship, (C) the plots of average alcohol consumption and frequency of going out with friends, and (D) the plots of average alcohol consumption and health. The boxplots, in particular, indicate the numbers of students consuming alcohol at every level of consumption (indicated by the y-axis on the left hand side) with the mean highlighted by the horizontal thick lin in each box. A trending up line of mean is clearly visible on panel C where higher frequency of going out with friends is associated with higher consumption of alcohol. And this is consistent with our hypothesis. The other three panels do not show clear relationships with the consumption level of alcohol. Nevertheless, we can still see the distributions, for instance in panel A, the highes level of alcohol consumption is on students aged 17-18 years old. On panel B, the highest level of mean is on family relationship level of 2 or bad relationship. On panel D, it seems that the consumption of alcohol is evenly distributed no matter the health condition is which is unappealing compared to our hypothesis.


```{r}
# First, the plots of alcohol consumption and age
temp <- mydata %>% group_by(age = factor(age)) %>% summarise(alc_use = mean(alc_use))
a <- ggplot(mydata, aes(factor(age), alc_use)) + geom_bar(data = temp, aes(age, alc_use), stat = "identity") + geom_boxplot()

# Second, the plots of alcohol consumption and family relation
temp <- mydata %>% group_by(famrel = factor(famrel)) %>% summarise(alc_use = mean(alc_use))
b <- ggplot(mydata, aes(factor(famrel), alc_use)) + geom_bar(data = temp, aes(famrel, alc_use), stat = "identity") + geom_boxplot()

# Third, the plots of alcohol consumption and 'go out with friends'
temp <- mydata %>% group_by(goout = factor(goout)) %>% summarise(alc_use = mean(alc_use))
c <- ggplot(mydata, aes(factor(goout), alc_use)) + geom_bar(data = temp, aes(goout, alc_use), stat = "identity") + geom_boxplot()

# Fourth, the plots of alcohol consumption and health condition
temp <- mydata %>% group_by(health = factor(health)) %>% summarise(alc_use = mean(alc_use))
d <- ggplot(mydata, aes(factor(health), alc_use)) + geom_bar(data = temp, aes(health, alc_use), stat = "identity") + geom_boxplot()

ggarrange(a, b, c, d, 
          labels = c("A", "B", "C", "D"),
          ncol = 2, nrow = 2)

```
\

## 3.3 Fit a logistic regression model

Our target (dependent) variable is the high consumption of alcohol and our regressors are the four variables of age, famrel, goout, health. The following R code estimates a logistic regression model using the glm (generalized linear model) function. 

```{r}
model <- glm( high_use ~ age + famrel + goout + health, data = mydata, family = binomial)
summary(model)
```
To interpret the results above, we adopt some materials from: https://stats.idre.ucla.edu/r/dae/logit-regression/.

From the summary of the fitted model above, the Deviance Residuals (displayed above the coefficients) indicate the distribution of the deviance residuals for individual cases used in the model. Moreover, we can measure the model fit using the results of Null deviance and the Residual deviance (displayed below the coefficients). We can test the significance of the overall model by comparing to the null model, i.e. the model with an intercept only (without the predictors). 

* First, we find the difference in deviance for the two competing models as for the test statistic as follows:

```{r}
with(model, null.deviance - deviance)
```
* The test statistic follows a chi-squared distribution with the degrees of freedom for the difference between the two competing models as follows:

```{r}
with(model, df.null - df.residual)
```
* Then we can compute the p-value as:

```{r}
with(model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```
* The chi-square of 63.56 with 4 degrees of freedom and a p-value of less than 0.001 shows that our model fits significantly better than an empty model or the null model.

Next we move to interpret the coefficients. Overall, together with the coefficients, the output also displays the standard errors, Wald z-statistic, and the p-values. From our four predictors, three are statistically significant, i.e. 'famre', 'goout', and 'health'. The coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable.

To interpret the coefficients as odds-ratios as well as their confidence intervals, we need to exponentiate the coefficients as follows:

```{r}
exp(cbind(OR = coef(model), confint(model)))
```
We can interpret the odds-ratios as follows:

* For one unit increase in 'famrel', there is a 36% lower likelihood of having high consumption of alcohol. Within 95% confidence interval, there is 16%-51% lower the likelihood of having high consumption of alcohol. As in the crosstabulation results, it contradicts with our previous hypothesis. It seems that we, as a data scientist, need to understand further the possibility of cultural aspect of consuming alcohol, in which more getting together with family, there is more probability of high consumption of alcohol.

* For one unit increase in 'goout', there is 2.20 times higher likelihood of having high consumption of alcohol. Within 95% confidence interval, the likelihood is 1.75-2.81 times higher. This is consistent with our hypothesis of more often going out with friends is associated with more consumption of alcohol.

* Lastly, for one unit increase in 'health', there is a 22% higher the likelihood of having high consumption of alcohol. Within 95% confidence interval, there is 2%-47% higher the likelihood of having high consumption of alcohol. This is also consistent with our hypothesis.

Next, we explore the predictive power of our model by provide a 2x2 cross tabulation of predictions versus the actual values and display a graphic visualizing both the actual values and the predictions.

```{r}
mydata$high_useP <- predict(model, newdata = mydata, type = "response")
mydata$high_useP = mydata$high_useP > 0.5
table(mydata$high_useP, mydata$high_use) #Produce 2x2 cross tabulation of predictions vs the actual values
```
\
The output displays a 2x2 matrix of the predictions and the actual values. We can see that there are 235+44=279 correct predictions or 75.41% out of 370 individuals. Hence the error is about 24.59%. When we see each actual values of FALSE and TRUE, out of 259 actual FALSE values, 235 predictions are correct and 24 predictions are wrong, so the error is about 9%. Then out of 111 actual TRUE values, 67 predictions are correct and 44 predictions are wrong, so the error is about 40%. Graphically, the proportions can be seen below.

```{r}
df <- as.data.frame(cbind(mydata$high_use, mydata$high_useP))

ggplot(df,aes(x = mydata$high_use, fill = mydata$high_useP)) + 
    geom_bar(position = "fill")
```
\
Now we compare the performance of the model with performance achieved by some simple guessing strategy. We use three variables of famrel, go out, and health as they are all statistically significant. Since they have the same scal of 1-5 and have positive correlation with the high consumption of alcohol, we simply predict that if the sum of the values of the three variables > 7.5, we predict that high consumption of alcohol is TRUE, otherwise it is FALSE. The output below shows 23+108=131 correct predictions or accuracy of 35.41% or the error is 64.59%, hence our model performs better.

```{r}
high_use_simpleP <- mydata$famrel+mydata$goout+mydata$health > 7.5
table(high_use_simpleP, mydata$high_use) #Produce 2x2 cross tabulation of simple predictions vs the actual values
```
\


## 3.4. Perform 10-fold cross-validation on the model

Here we perform 10-fold cross-validation of the model using the 'caret' package in R as follows:

```{r}
# define training control
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
modelcv <- train(factor(high_use) ~ age + famrel + goout + health,
               data = mydata,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
modelcv
```
Note that, 'caret' package is an optimist, and prefers to report accuracy (proportion of correct classifications) instead of the error (proportion of incorrect classifications). So, referring to our result here, Accuracy of 0.74 is equivalent to error of 0.26 or just about the same with the model introduced in DataCamp (which had about 0.26 error).

In case we want to take into account the uncertainty in our accuracy estimate, we may consider the accuracy standard deviation as presented below:

```{r}
modelcv$results
```

Given the AccuracySD of about 0.04, then our accuracy is around 0.70-0.78.

## 3.5 Perform cross-validation to compare the performance of different logistic regression models

We start with a very high number of predictors and explore the changes in the training and testing errors as we move to models with less predictors.

First, we include 34 predictors in our dataset. It turns out that we get the accuracy of 0.997 or just 0.003 error. However, we also get a warning that the glm.fit algorith did not converge meaning that the prediction of our estimate may be misleading. See the R script and its output below.

```{r, warning = FALSE}
# define training control
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
modelcv2 <- train(factor(high_use) ~ .,
               data = mydata,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
modelcv2$results
```
\
Second, we include < 34 predictors, i.e. 17 predictors. It turns out that we get the accuracy of 0.754 or just 0.0.246 error. It seems that we get a better accuracy or a lower error compared to the 4-predictor model. See the R script and its output below.

```{r}
# define training control
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
modelcv3 <- train(factor(high_use) ~ age + famrel + goout + health + school + sex + Medu + Fedu + Mjob + Fjob + studytime + traveltime + nursery + higher + internet + freetime + G3,
               data = mydata,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
modelcv3
```
Third, we experiment with 10 predictors without our chosen 4-predictor as in our original model. Now we get accuracy score of 0.711 or 0.289 error, a higher error than our original 4-predictor model. Hence, we conjecture that there is an optimum point to get the best model (which has the highest accuracy or the lowest error) conditional on the predictors to be used. More predictors do not guarantee better results, but more **appropriate** predictors do.

```{r}
# define training control
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
modelcv4 <- train(factor(high_use) ~ guardian + school + sex + studytime + traveltime + nursery + higher + internet + freetime + G3,
               data = mydata,
               trControl = train_control,
               method = "glm",
               family=binomial())

# print cv scores
modelcv4
```
Finally, we draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. It suggests that the best results we can get is by having 5-7 predictors only in the model. It will give accuracy of 0.849-0.851 or 0.149-0.151 error. See the R scripts and outputs below.

```{r}
highuse_knn_mod = train(
  factor(high_use) ~ .,
  data = mydata,
  method = "knn",
  trControl = trainControl(method = "cv", number = 10),
  preProcess = c("center", "scale"),
  tuneGrid = expand.grid(k = seq(1, 34, by = 2))
)

ggplot(highuse_knn_mod) + theme_bw()

```
```{r}
#highuse_knn_mod$bestTune
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
get_best_result(highuse_knn_mod)
```

_This is the end of the report_

```{r}
date()

```


